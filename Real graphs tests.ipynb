{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7054c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "import sys\n",
    "sys.path += ['Package/']  \n",
    "\n",
    "from node2vec.model import Node2Vec\n",
    "\n",
    "from node_embedding import *\n",
    "from dcsbm import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "directory = 'dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05bc172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunSimulation():\n",
    "\n",
    "    datasets = ['amazon', 'dblp', 'livejournal', 'youtube']\n",
    "    \n",
    "    tv = []\n",
    "    tnsv = []\n",
    "    sv = []\n",
    "    snsv = []\n",
    "\n",
    "    for name in datasets:\n",
    "\n",
    "        EL = pd.read_csv(directory + name + '.csv')[['id1', 'id2']]\n",
    "        n = len(pd.concat([EL.id1, EL.id2]).unique())\n",
    "\n",
    "        ℓtrue = pd.read_csv(directory + name + '_label.csv').set_index('node')\n",
    "        ℓtrue = ℓtrue.loc[np.arange(n)].label.values\n",
    "        n_clusters = len(np.unique(ℓtrue))\n",
    "\n",
    "        A = csr_matrix((np.ones(len(EL)), (EL.id1, EL.id2)), shape = (n,n))    \n",
    "        d = A@np.ones(A.shape[0])\n",
    "\n",
    "        t0 = time.time()\n",
    "        dim = 128\n",
    "        f_func = lambda x:np.sqrt(x)\n",
    "        Φ = NodeEmbedding(A, dim, f_func = f_func, η = .85, n_epochs = 30, n_prod = 1, \n",
    "                          verbose = True, cov_type = 'full')\n",
    "        t = time.time() - t0\n",
    "        s = computeScore(Φ, ℓtrue, n_trials = 1, norm_bool = True)\n",
    "\n",
    "        t0 = time.time()\n",
    "        X = Node2VecNS(A, dim, verbose = True)\n",
    "        tns = time.time() - t0\n",
    "        sns = computeScore(X, ℓtrue, n_trials = 1)\n",
    "    \n",
    "        tv.append(t)\n",
    "        tnsv.append(tns)\n",
    "        sv.append(s)\n",
    "        snsv.append(sns)\n",
    "       \n",
    "    df = pd.DataFrame(columns = datasets)\n",
    "    df_time = pd.DataFrame(columns = datasets)\n",
    "    \n",
    "    row = dict(zip(datasets, sv))\n",
    "    df = df.append(row, ignore_index = True)\n",
    "    row = dict(zip(datasets, tv))\n",
    "    df_time = df_time.append(row, ignore_index = True)\n",
    "    \n",
    "    row = dict(zip(datasets, snsv))\n",
    "    df = df.append(row, ignore_index = True)\n",
    "    row = dict(zip(datasets, tnsv))\n",
    "    df_time = df_time.append(row, ignore_index = True)\n",
    "    \n",
    "   # save the result\n",
    "    try:\n",
    "        nn = (np.max([int(x.split('_')[1]) for x in listdir('saved_files/real_graphs/perf/')]))\n",
    "        df.to_csv('saved_files/real_graphs/perf/v_' + str(nn+1) + '_.csv', index = False)\n",
    "        df_time.to_csv('saved_files/real_graphs/time/v_' + str(nn+1) + '_.csv', index = False)\n",
    "\n",
    "    except:\n",
    "        df.to_csv('saved_files/real_graphs/perf/v_' + str(1) + '_.csv', index = False)\n",
    "        df_time.to_csv('saved_files/real_graphs/time/v_' + str(1) + '_.csv', index = False)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82681805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the optimization for k = 1\n",
      "Preprocessing progress: 0%Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 94.45%cessing progress: 81.57%81.57%78.35%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 96.6%%5.13%%ress: 00%%0%0%0%0%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "Preprocessing progress: 000%%0%Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 95.16%cessing progress: 94.66%94.6694.66%%ress: 89.7189.71%89.71%Preprocessing progress: \n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 99.12%6.17%%ress: 000%%%00\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "[========================>] 100%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 64504 points to 1662 centroids: please provide at least 64818 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing progress: 4.186%%essing progress: 0%00% the Skip-Gram model...\n",
      "Preprocessing progress: 98.6%%97.67%g progress: 95.3495.34%%ng progress: \n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 99.22%g progress: 86.8286.82%%progress: 0%0%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 64504 points to 1662 centroids: please provide at least 64818 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the optimization for k = 1\n",
      "Preprocessing progress: 0%Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 98.77%79.46%g progress: 27.85%27.85%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 96.54%g progress: 0%0%0%g progress: Walking progress: 0%0%0%0%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 94.45%85.86%g progress: 39.71%39.71%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 96.6%%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "Preprocessing proLearning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 95.32%4.5%7%g progress: 93.0193.0193.01%%%ress: 91.86%91.8691.86%%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 99.12%9.56%%ress: 21.4821.48%%rogress: 0%%00%%0%0%0%: Walking progress: \n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "[========================>] 100%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 64504 points to 1662 centroids: please provide at least 64818 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing progress: 00%%Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 98.75%cessing progress: 98.29%98.29%96.43%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 99.22%g progress: 69.7669.76%%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 64504 points to 1662 centroids: please provide at least 64818 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the optimization for k = 1\n",
      "Preprocessing progress: 0000%%%%Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 98.77%96.17%g progress: 90.23%90.23%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 96.54%king progress: 0%0%0%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "Preprocessing progress: 95.52%cessing progress: 89.0889.08%%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 96.6%%king progress: 0%0%Walking progress: 0%0%0%0%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings using the Skip-Gram model...\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "Preprocessing progress: 0000%%%0%%Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 95.32%95.32%91.36%ress: 91.19%91.19%85.41%ress: 85.41%85.41%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 99.12%1.39%%ress: Walking progress: Walking progress: \n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "[========================>] 100%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 64504 points to 1662 centroids: please provide at least 64818 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing progress: 0%0Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 98.91%3.64%%Preprocessing progress: 89.92%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 99.22%g progress: 34.11%34.11%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 64504 points to 1662 centroids: please provide at least 64818 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the optimization for k = 1\n",
      "Preprocessing progress: Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 98.4%98.4%%%g progress: 97.66%97.66%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 96.54%king progress: %0%g progress: Walking progress: Walking progress: 000%%00%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "Preprocessing progress: 32.2%ocessing progress: 31.1331.13%%ip-Gram model...\n",
      "Preprocessing progress: Preprocessing progress: 94.45%94.45%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 96.6%%ng progress: %00%0%ng progress: \n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "Preprocessing progress: Preprocessing progress: 00%%Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: Preprocessing progress: 95.3295.32%%g progress: 94.17%94.1794.17%%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 97.47%g progress: Walking progress: Walking progress: Walking progress: 00%00%%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "[========================>] 100%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 64504 points to 1662 centroids: please provide at least 64818 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 98.75%cessing progress: 96.89%96.89%ess: 78.91%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 99.22%3.95%%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 64504 points to 1662 centroids: please provide at least 64818 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the optimization for k = 1\n",
      "Preprocessing progress: 10.03%%0%0%%g progress: Preprocessing progress: \n",
      "Preprocessing progress: Preprocessing progress: 98.7798.77%%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 96.54%g progress: 37.1337.13%%ress: Walking progress: 0%000%%%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "Preprocessing progress: Preprocessing progress: 00%0%%Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: Preprocessing progress: 94.45%94.45%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 96.6%%0% progress: 0%0%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "Preprocessing progress: 00%%Learning embeddings using the Skip-Gram model...\n",
      "95.32Preproce progress: 95.16%95.16%g progress: 94.17%94.17%Preprocessing progress: 85.74%ssing progress: %95.32%95.32%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 99.12%g progress: 44.6144.61%% progress: %0%0%Walking progress: 0%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n",
      "Running the optimization for k = 1\n",
      "[========================>] 100%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 64504 points to 1662 centroids: please provide at least 64818 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing progress: 00%Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 98.75%8.13%%g progress: 93.64%93.64%93.17%sing progress: 34.57%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 97.67%g progress: 37.2137.21%%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 64504 points to 1662 centroids: please provide at least 64818 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the optimization for k = 1\n",
      "Preprocessing progress: 1Learning embeddings using the Skip-Gram model...\n",
      "Preprocessing progress: 98.4%%cessing progress: 97.29%97.29%\n",
      "Preprocessing transition probabilities: done!\n",
      "Walking progress: 96.54%18.57%ress: 00%00%\n",
      "Simulating random walks: done!\n",
      "Learning embeddings: done!\n"
     ]
    }
   ],
   "source": [
    "n_sim = 5\n",
    "\n",
    "for i in range(n_sim):\n",
    "    RunSimulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247cb5fe",
   "metadata": {},
   "source": [
    "| Dataset     | NMI f | NMI NS | t us | t NS  |\n",
    "| -------     | ----- | ------ | ---- | ----- |\n",
    "| amazon      | 0.93  | 0.93   | 1    | 16    |\n",
    "| dblp        | 0.52  | 0.51   | 9    | 116   |\n",
    "| livejournal | 0.92  | 0.91   | 13   | 137   |\n",
    "| youtube     | 0.60  | 0.63   | 4    | 54    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e877edc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         amazon      dblp  livejournal   youtube\n",
      "index                                           \n",
      "0      0.924100  0.517563     0.915837  0.602270\n",
      "1      0.934434  0.509894     0.912073  0.652542\n",
      "          amazon        dblp  livejournal    youtube\n",
      "index                                               \n",
      "0       3.688894   25.905197    33.536647  11.452375\n",
      "1      16.448200  179.075804   195.456344  71.530425\n"
     ]
    }
   ],
   "source": [
    "files = listdir('saved_files/real_graphs/perf/')\n",
    "\n",
    "df_list_perf = []\n",
    "df_list_time = []\n",
    "\n",
    "for f in files:\n",
    "    df_list_perf.append(pd.read_csv('saved_files/real_graphs/perf/' + f))\n",
    "    df_list_time.append(pd.read_csv('saved_files/real_graphs/time/' + f))\n",
    "    \n",
    "df_list_perf = pd.concat(df_list_perf).reset_index()\n",
    "df_list_time = pd.concat(df_list_time).reset_index()\n",
    "\n",
    "print(df_list_perf.groupby('index').mean())\n",
    "print(df_list_time.groupby('index').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada850fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
