{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63dcc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "import numpy as np\n",
    "\n",
    "directory = '/home/lorenzo/Scrivania/My_projects/DeepWalk/P2Vec/dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d82f1f5",
   "metadata": {},
   "source": [
    "# Con questo siamo a posto... devo solo aggiungere poi una descrizione dettagliata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8072b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "name = 'orkut'\n",
    "\n",
    "with open(directory + 'labels_' + name + '.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    \n",
    "\n",
    "df = pd.read_csv(directory + name + '.txt', skiprows = 4, header = None, sep = \"\\t\")\n",
    "df.rename(columns={0: \"idx1\", 1: \"idx2\"}, inplace = True)\n",
    "\n",
    "# keep only the clusters with a size above a threshold\n",
    "min_cluster_size = 20\n",
    "assignment = []\n",
    "for l in lines:\n",
    "    a = l.split(\"\\n\")[0].split(\"\\t\")\n",
    "    if len(a) > min_cluster_size:\n",
    "        assignment.append([int(x) for x in a])\n",
    "\n",
    "# assign each node to the largest cluster they belong to\n",
    "label_dict = dict()\n",
    "for i, a in enumerate(assignment):\n",
    "    for j in a:\n",
    "        if j not in label_dict.keys():\n",
    "            label_dict[j] = [i]\n",
    "        else:\n",
    "            label_dict[j].append(i)\n",
    "\n",
    "sizes = np.array([len(a) for a in assignment])\n",
    "\n",
    "for x in label_dict.keys():\n",
    "    label_dict[x] = label_dict[x][np.argmax(sizes[label_dict[x]])]\n",
    "\n",
    "# sample down the network to the nodes actually appearing\n",
    "all_nodes = list(label_dict.keys())\n",
    "df = df[np.isin(df.idx1, all_nodes)]\n",
    "df = df[np.isin(df.idx2, all_nodes)]\n",
    "\n",
    "all_nodes = np.unique(np.concatenate([df.idx1, df.idx2]))\n",
    "n = len(all_nodes)\n",
    "mapper = dict(zip(all_nodes, np.arange(n)))\n",
    "\n",
    "# obtain the label vector\n",
    "ℓtrue = np.zeros(n)\n",
    "for x in all_nodes:\n",
    "    ℓtrue[mapper[x]] = label_dict[x]\n",
    "\n",
    "EL = df.values\n",
    "\n",
    "idx1 = [mapper[a] for a in EL[:,0]]\n",
    "idx2 = [mapper[a] for a in EL[:,1]]\n",
    "\n",
    "df = pd.DataFrame(columns = ['id1', 'id2'])\n",
    "df.id1 = np.concatenate([idx1, idx2])\n",
    "df.id2 = np.concatenate([idx2, idx1])\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "df.to_csv(directory + name + '.csv')\n",
    "    \n",
    "label_df = pd.DataFrame(columns = ['node', 'label'])\n",
    "label_df.node = np.arange(n)\n",
    "label_df.label = ℓtrue\n",
    "label_df.set_index('node', inplace = True)\n",
    "\n",
    "\n",
    "label_df.to_csv(directory + name + '_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c488b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
